{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/monk/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import networkx as nx\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "\n",
    "learning_rate =  0.01\n",
    "epochs        =  20\n",
    "hidden1       =  32\n",
    "hidden2       =  16\n",
    "dropout       =  0.1\n",
    "\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    g = nx.read_edgelist('./yeast.edgelistj')\n",
    "    adj = nx.adjacency_matrix(g)\n",
    "    return adj\n",
    "\n",
    "# g = nx.read_edgelist('./yeast.edgelistj')\n",
    "# adj = nx.adjacency_matrix(g)\n",
    "\n",
    "\n",
    "def weight_variable_glorot(input_dim, output_dim, name=\"\"):\n",
    "    init_range = np.sqrt(6.0 / (input_dim + output_dim))\n",
    "    initial = tf.random_uniform(\n",
    "        [input_dim, output_dim], minval=-init_range,\n",
    "        maxval=init_range, dtype=tf.float32)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "\n",
    "def dropout_sparse(x, keep_prob, num_nonzero_elems):\n",
    "    noise_shape = [num_nonzero_elems]\n",
    "    random_tensor = keep_prob\n",
    "    random_tensor += tf.random_uniform(noise_shape)\n",
    "    dropout_mask = tf.cast(tf.floor(random_tensor), dtype=tf.bool)\n",
    "    pre_out = tf.sparse_retain(x, dropout_mask)\n",
    "    return pre_out * (1. / keep_prob)\n",
    "\n",
    "\n",
    "def sparse_to_tuple(sparse_mx):\n",
    "    if not sp.isspmatrix_coo(sparse_mx):\n",
    "        sparse_mx = sparse_mx.tocoo()\n",
    "    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n",
    "    values = sparse_mx.data\n",
    "    shape = sparse_mx.shape\n",
    "    return coords, values, shape\n",
    "\n",
    "\n",
    "def preprocess_graph(adj):\n",
    "    adj = sp.coo_matrix(adj)\n",
    "    adj_ = adj + sp.eye(adj.shape[0])\n",
    "    rowsum = np.array(adj_.sum(1))\n",
    "    degree_mat_inv_sqrt = sp.diags(np.power(rowsum, -0.5).flatten())\n",
    "    adj_normalized = adj_.dot(degree_mat_inv_sqrt).transpose().dot(degree_mat_inv_sqrt).tocoo()\n",
    "    return sparse_to_tuple(adj_normalized)\n",
    "\n",
    "\n",
    "def construct_feed_dict(adj_normalized, adj, features, placeholders):\n",
    "    feed_dict = dict()\n",
    "    feed_dict.update({placeholders['features']: features})\n",
    "    feed_dict.update({placeholders['adj']: adj_normalized})\n",
    "    feed_dict.update({placeholders['adj_orig']: adj})\n",
    "    return feed_dict\n",
    "\n",
    "\n",
    "def mask_test_edges(adj):\n",
    "    # Function to build test set with 2% positive links\n",
    "    # Remove diagonal elements\n",
    "    adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n",
    "    adj.eliminate_zeros()\n",
    "\n",
    "    adj_triu = sp.triu(adj)\n",
    "    adj_tuple = sparse_to_tuple(adj_triu)\n",
    "    edges = adj_tuple[0]\n",
    "    edges_all = sparse_to_tuple(adj)[0]\n",
    "    num_test = int(np.floor(edges.shape[0] / 50.))\n",
    "    num_val = int(np.floor(edges.shape[0] / 50.))\n",
    "\n",
    "    all_edge_idx = list(range(edges.shape[0]))\n",
    "    np.random.shuffle(all_edge_idx)\n",
    "    val_edge_idx = all_edge_idx[:num_val]\n",
    "    test_edge_idx = all_edge_idx[num_val:(num_val + num_test)]\n",
    "    test_edges = edges[test_edge_idx]\n",
    "    val_edges = edges[val_edge_idx]\n",
    "    train_edges = np.delete(edges, np.hstack([test_edge_idx, val_edge_idx]), axis=0)\n",
    "\n",
    "    def ismember(a, b):\n",
    "        rows_close = np.all((a - b[:, None]) == 0, axis=-1)\n",
    "        return np.any(rows_close)\n",
    "\n",
    "    test_edges_false = []\n",
    "    while len(test_edges_false) < len(test_edges):\n",
    "        n_rnd = len(test_edges) - len(test_edges_false)\n",
    "        rnd = np.random.randint(0, adj.shape[0], size=2 * n_rnd)\n",
    "        idxs_i = rnd[:n_rnd]                                        \n",
    "        idxs_j = rnd[n_rnd:]\n",
    "        for i in range(n_rnd):\n",
    "            idx_i = idxs_i[i]\n",
    "            idx_j = idxs_j[i]\n",
    "            if idx_i == idx_j:\n",
    "                continue\n",
    "            if ismember([idx_i, idx_j], edges_all):\n",
    "                continue\n",
    "            if test_edges_false:\n",
    "                if ismember([idx_j, idx_i], np.array(test_edges_false)):\n",
    "                    continue\n",
    "                if ismember([idx_i, idx_j], np.array(test_edges_false)):\n",
    "                    continue\n",
    "            test_edges_false.append([idx_i, idx_j])\n",
    "\n",
    "    val_edges_false = []\n",
    "    while len(val_edges_false) < len(val_edges):\n",
    "        n_rnd = len(val_edges) - len(val_edges_false)\n",
    "        rnd = np.random.randint(0, adj.shape[0], size=2 * n_rnd)\n",
    "        idxs_i = rnd[:n_rnd]                                        \n",
    "        idxs_j = rnd[n_rnd:]\n",
    "        for i in range(n_rnd):\n",
    "            idx_i = idxs_i[i]\n",
    "            idx_j = idxs_j[i]\n",
    "            if idx_i == idx_j:\n",
    "                continue\n",
    "            if ismember([idx_i, idx_j], train_edges):\n",
    "                continue\n",
    "            if ismember([idx_j, idx_i], train_edges):\n",
    "                continue\n",
    "            if ismember([idx_i, idx_j], val_edges):\n",
    "                continue\n",
    "            if ismember([idx_j, idx_i], val_edges):\n",
    "                continue\n",
    "            if val_edges_false:\n",
    "                if ismember([idx_j, idx_i], np.array(val_edges_false)):\n",
    "                    continue\n",
    "                if ismember([idx_i, idx_j], np.array(val_edges_false)):\n",
    "                    continue\n",
    "            val_edges_false.append([idx_i, idx_j])\n",
    "\n",
    "    # Re-build adj matrix\n",
    "    data = np.ones(train_edges.shape[0])\n",
    "    adj_train = sp.csr_matrix((data, (train_edges[:, 0], train_edges[:, 1])), shape=adj.shape)\n",
    "    adj_train = adj_train + adj_train.T\n",
    "\n",
    "    return adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false\n",
    "\n",
    "\n",
    "def get_roc_score(edges_pos, edges_neg,ouy):\n",
    "    feed_dict.update({placeholders['dropout']: 0})\n",
    "    emb = sess.run(ouy, feed_dict=feed_dict)\n",
    "\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    # Predict on test set of edges\n",
    "    adj_rec = np.dot(emb, emb.T)\n",
    "    preds = []\n",
    "    pos = []\n",
    "    for e in edges_pos:\n",
    "        preds.append(sigmoid(adj_rec[e[0], e[1]]))\n",
    "        pos.append(adj_orig[e[0], e[1]])\n",
    "\n",
    "    preds_neg = []\n",
    "    neg = []\n",
    "    for e in edges_neg:\n",
    "        preds_neg.append(sigmoid(adj_rec[e[0], e[1]]))\n",
    "        neg.append(adj_orig[e[0], e[1]])\n",
    "\n",
    "    preds_all = np.hstack([preds, preds_neg])\n",
    "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds))])\n",
    "    roc_score = roc_auc_score(labels_all, preds_all)\n",
    "    ap_score = average_precision_score(labels_all, preds_all)\n",
    "\n",
    "    return roc_score, ap_score\n",
    "\n",
    "\n",
    "adj = load_data()\n",
    "num_nodes = adj.shape[0]\n",
    "num_edges = adj.sum()\n",
    "# Featureless\n",
    "features = sparse_to_tuple(sp.identity(num_nodes))\n",
    "num_features = features[2][1]\n",
    "features_nonzero = features[1].shape[0]\n",
    "\n",
    "# Store original adjacency matrix (without diagonal entries) for later\n",
    "adj_orig = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n",
    "adj_orig.eliminate_zeros()\n",
    "\n",
    "adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(adj)\n",
    "adj = adj_train\n",
    "\n",
    "adj_norm = preprocess_graph(adj)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "placeholders = {\n",
    "    'features': tf.sparse_placeholder(tf.float32),\n",
    "    'adj': tf.sparse_placeholder(tf.float32),\n",
    "    'adj_orig': tf.sparse_placeholder(tf.float32),\n",
    "    'dropout': tf.placeholder_with_default(0., shape=())\n",
    "}\n",
    "\n",
    "input_dim           = num_features\n",
    "features_nonzero    = features_nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('yeast_gcn'):\n",
    "    \n",
    "    with tf.name_scope('gcn_sparse_layer'):\n",
    "        \n",
    "        x = placeholders['features']\n",
    "        x = dropout_sparse(x, 1-placeholders['dropout'], features_nonzero)\n",
    "        vars_km ={}\n",
    "        with tf.variable_scope('gcn_sparse_layer_vars'):\n",
    "            vars_km['weights'] = weight_variable_glorot(num_features, hidden1, name='weights')\n",
    "\n",
    "        x = tf.sparse_tensor_dense_matmul(x, vars_km['weights'])\n",
    "        x = tf.sparse_tensor_dense_matmul(placeholders['adj'], x)\n",
    "        outputs_one = tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('yeast_gcn'):\n",
    "    \n",
    "\n",
    "    with tf.name_scope('gcn_dense_layer'):\n",
    "        x = outputs_one\n",
    "        x = tf.nn.dropout(x, 1- placeholders['dropout'])\n",
    "\n",
    "        var_m = {}\n",
    "        with tf.variable_scope('gcn_dense_layer' + '_vars'):\n",
    "            var_m['weights'] = weight_variable_glorot(hidden1,hidden2,name='weights')\n",
    "\n",
    "        x = tf.matmul(x, var_m['weights'])\n",
    "        x = tf.sparse_tensor_dense_matmul(placeholders['adj'], x)\n",
    "        outputs_two = x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('yeast_gcn'):\n",
    "    \n",
    "    with tf.name_scope('gcn_decoder'):\n",
    "        inputss = tf.nn.dropout(outputs_two, 1- placeholders['dropout'])\n",
    "        x = tf.transpose(inputss)\n",
    "        x = tf.matmul(inputss, x)\n",
    "        x = tf.reshape(x, [-1])\n",
    "        outputs_three = x\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('optimizer'):\n",
    "    \n",
    "    pos_weight = float(num_nodes**2 - num_edges) / num_edges\n",
    "    norm = num_nodes**2 / float((num_nodes**2 - num_edges) * 2)\n",
    "    preds_sub = outputs_three\n",
    "    labels_sub = tf.reshape(tf.sparse_tensor_to_dense(placeholders['adj_orig'], validate_indices=False), [-1])\n",
    "\n",
    "    cost = norm * tf.reduce_mean(\n",
    "        tf.nn.weighted_cross_entropy_with_logits(\n",
    "                    logits=preds_sub, targets=labels_sub, pos_weight=pos_weight))\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate= learning_rate)  # Adam Optimizer\n",
    "\n",
    "    opt_op = optimizer.minimize(cost)\n",
    "    grads_vars = optimizer.compute_gradients(cost)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "adj_label = adj_train + sp.eye(adj_train.shape[0])\n",
    "adj_label = sparse_to_tuple(adj_label)\n",
    "\n",
    "# Train model\n",
    "for epoch in range(epochs):\n",
    "    t = time.time()\n",
    "    # Construct feed dictionary\n",
    "    feed_dict = construct_feed_dict(adj_norm, adj_label, features, placeholders)\n",
    "    feed_dict.update({placeholders['dropout']: dropout})\n",
    "    # One update of parameter matrices\n",
    "    _, avg_cost = sess.run([opt_op, cost], feed_dict=feed_dict)\n",
    "    # Performance on validation set\n",
    "    roc_curr, ap_curr = get_roc_score(val_edges, val_edges_false,outputs_two)\n",
    "\n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1), \n",
    "          \"train_loss=\", \"{:.5f}\".format(avg_cost),\n",
    "          \"val_roc=\", \"{:.5f}\".format(roc_curr),\n",
    "          \"val_ap=\", \"{:.5f}\".format(ap_curr),\n",
    "          \"time=\", \"{:.5f}\".format(time.time() - t))\n",
    "\n",
    "print('Optimization Finished!')\n",
    "\n",
    "roc_score, ap_score = get_roc_score(test_edges, test_edges_false)\n",
    "print('Test ROC score: {:.5f}'.format(roc_score))\n",
    "print('Test AP score: {:.5f}'.format(ap_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
